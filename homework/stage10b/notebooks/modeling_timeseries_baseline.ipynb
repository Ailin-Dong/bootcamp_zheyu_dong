{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c77fbb",
   "metadata": {},
   "source": [
    "# Stage 10b — Time Series Baseline (Features, Pipeline, Evaluation)\n",
    "\n",
    "**Chain statement:** In the lecture, we learned how to create lag/rolling features, build pipelines, and evaluate with appropriate metrics. Now we adapt those patterns to a simple time series to produce a validated baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2916eb",
   "metadata": {},
   "source": [
    "## 1) Load & Prepare Dataset (DateTime index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a03987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"../data/raw/time_series.csv\")\n",
    "df = pd.read_csv(DATA, parse_dates=[\"date\"]).sort_values(\"date\").set_index(\"date\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c1e89",
   "metadata": {},
   "source": [
    "## 2) Engineer Features (lag/rolling/momentum/z-score)\n",
    "- Avoid leakage by **shifting** roll/lag so features at *t* use info up to *t-1*.\n",
    "- Target for forecasting: **next-step return** `y = ret.shift(-1)` (drop tail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3542085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 2.1 returns\n",
    "df[\"ret\"] = df[\"price\"].pct_change()\n",
    "\n",
    "# 2.2 engineered features (all based on *past* info)\n",
    "# lags\n",
    "df[\"lag1_ret\"] = df[\"ret\"].shift(1)\n",
    "df[\"lag5_ret\"] = df[\"ret\"].shift(5)\n",
    "\n",
    "# rolling stats on returns (shifted by 1 to avoid using t info)\n",
    "df[\"roll_mean_5\"] = df[\"ret\"].rolling(window=5).mean().shift(1)\n",
    "df[\"roll_std_5\"]  = df[\"ret\"].rolling(window=5).std().shift(1)\n",
    "\n",
    "# rolling min/max on price (shifted)\n",
    "df[\"roll_min_10\"] = df[\"price\"].rolling(window=10).min().shift(1)\n",
    "df[\"roll_max_10\"] = df[\"price\"].rolling(window=10).max().shift(1)\n",
    "\n",
    "# momentum (10-day)\n",
    "df[\"mom_10\"] = (df[\"price\"] / df[\"price\"].shift(10)) - 1\n",
    "\n",
    "# rolling z-score of price (20-day)\n",
    "mean20 = df[\"price\"].rolling(20).mean().shift(1)\n",
    "std20  = df[\"price\"].rolling(20).std().shift(1)\n",
    "df[\"zscore_20\"] = (df[\"price\"] - mean20) / std20\n",
    "\n",
    "# 2.3 target: next-step return\n",
    "df[\"y\"] = df[\"ret\"].shift(-1)\n",
    "\n",
    "# drop warmup NaNs\n",
    "df_feat = df.dropna().copy()\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54614c8",
   "metadata": {},
   "source": [
    "### Notes on leakage & rationale\n",
    "- **Leakage control**: `.shift(1)` on lags/rolling stats ensures only past info is used for features at time *t*.\n",
    "- **Feature choices**:\n",
    "  - `lag1_ret`, `lag5_ret`: short-term memory of returns。\n",
    "  - `roll_mean_5`, `roll_std_5`: local trend & volatility。\n",
    "  - `roll_min_10`, `roll_max_10`: local bounds (support/resistance proxy)。\n",
    "  - `mom_10`: momentum signal。\n",
    "  - `zscore_20`: relative deviation from recent mean。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724c1c5",
   "metadata": {},
   "source": [
    "## 3) Time-aware Split (last 25% as test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1179607",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(df_feat)\n",
    "cut = int(n * 0.75)\n",
    "train = df_feat.iloc[:cut].copy()\n",
    "test  = df_feat.iloc[cut:].copy()\n",
    "\n",
    "features = [\"lag1_ret\",\"lag5_ret\",\"roll_mean_5\",\"roll_std_5\",\"roll_min_10\",\"roll_max_10\",\"mom_10\",\"zscore_20\"]\n",
    "X_train, y_train = train[features], train[\"y\"]\n",
    "X_test,  y_test  = test[features],  test[\"y\"]\n",
    "\n",
    "len(train), len(test), X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba45ca",
   "metadata": {},
   "source": [
    "## 4) Build sklearn Pipeline (preprocessing → model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ae195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", Ridge(alpha=1.0))\n",
    "])\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142dae70",
   "metadata": {},
   "source": [
    "## 5) Fit → Predict → Evaluate (MAE/RMSE) + Plot prediction vs truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf29c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pred_train = pipe.predict(X_train)\n",
    "pred_test  = pipe.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, pred_train)\n",
    "rmse_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "mae_test = mean_absolute_error(y_test, pred_test)\n",
    "rmse_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "\n",
    "print(\"MAE  (train, test):\", round(mae_train,6), round(mae_test,6))\n",
    "print(\"RMSE (train, test):\", round(rmse_train,6), round(rmse_test,6))\n",
    "\n",
    "# Plot prediction vs truth on test\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test.index, y_test.values, label=\"truth\")\n",
    "plt.plot(y_test.index, pred_test, label=\"prediction\")\n",
    "plt.title(\"Next-step return: prediction vs truth (test)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80254c3e",
   "metadata": {},
   "source": [
    "## 6) (Optional) Classification baseline\n",
    "If you prefer classification: `y_up = (ret.shift(-1) > 0).astype(int)` then train a classifier.\n",
    "Below is a compact example with `LogisticRegression` and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "cls_train = (train[\"y\"] > 0).astype(int)\n",
    "cls_test  = (test[\"y\"] > 0).astype(int)\n",
    "\n",
    "clf = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                (\"clf\", LogisticRegression(max_iter=1000))])\n",
    "clf.fit(X_train, cls_train)\n",
    "pred_cls = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(cls_test, pred_cls)\n",
    "prec = precision_score(cls_test, pred_cls, zero_division=0)\n",
    "rec = recall_score(cls_test, pred_cls, zero_division=0)\n",
    "f1 = f1_score(cls_test, pred_cls, zero_division=0)\n",
    "\n",
    "print({\"accuracy\":acc, \"precision\":prec, \"recall\":rec, \"f1\":f1})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "disp = ConfusionMatrixDisplay.from_predictions(cls_test, pred_cls)\n",
    "plt.title(\"Confusion Matrix (test)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5abee",
   "metadata": {},
   "source": [
    "## 7) Interpretation — what works, what fails, assumptions\n",
    "- **Works**: Lag/rolling features provide a modest signal; scaling + Ridge yields a stable baseline。\n",
    "- **Fails**: 高噪声时序下，短期可预测性弱；波动突变会降低性能。\n",
    "- **Assumptions risk**: 平稳性与弱依赖假设可能不成立；若存在概念漂移，固定窗口特征失效；请避免泄漏（窗口与 shift 要严格）。\n",
    "- **Next steps**: 调参（alpha、窗口长度）、增补特征（季节性、节假日）、尝试更稳健损失或非线性模型（但先保留可解释基线）。"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
